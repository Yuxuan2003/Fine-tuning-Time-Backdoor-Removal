{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import random\n",
    "# from defense_channel_lips import CLP\n",
    "from models.simclr_model import SimCLR\n",
    "import numpy \n",
    "import cv2\n",
    "import numpy as np\n",
    "from datasets.backdoor_dataset import CIFAR10Mem, CIFAR10Pair, BadEncoderTestBackdoor, ReferenceImg, BadEncoderDataset,BadEncoderTrainBackdoor,BadEncoderTrainBackdoorwithpoisonlabel\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from evaluation.nn_classifier import create_torch_dataloader,predict_feature,net_train,net_test_with_logger,net_test,NeuralNet\n",
    "import copy\n",
    "\n",
    "##################prepare_model\n",
    "def val(net, data_loader):\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        n_correct = 0\n",
    "        n_total = 0\n",
    "\n",
    "        for images, targets  in data_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "            logits = net(images)\n",
    "            prediction = logits.argmax(-1)\n",
    "\n",
    "            n_correct += (prediction==targets).sum()\n",
    "            n_total += targets.shape[0]\n",
    "            \n",
    "        acc = n_correct / n_total * 100\n",
    "\n",
    "    return acc\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, first_model, second_model):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.first_model = first_model\n",
    "        self.second_model = second_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        output_first_model = self.first_model(x)\n",
    "        second_input = F.normalize(output_first_model,dim=1)\n",
    "        output_second_model = self.second_model(second_input)\n",
    "        return output_second_model\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimCLR()\n",
    "# model.load_state_dict(torch.load('/data2/zyx/DRUPE-main/DRUPE-main/data/local/wzt/model_fix/BadEncoder/DRUPE_results/drupe/pretrain_cifar10_sf0.2/downstream_stl10_t0/epoch120.pth')['state_dict'])\n",
    "model.load_state_dict(torch.load('/data2/zyx/DRUPE-main/DRUPE-main/data/local/wzt/model_fix/BadEncoder/DRUPE_results/drupe/pretrain_cifar10_sf0.2/downstream_gtsrb_t12/epoch120.pth')['state_dict'])\n",
    "# model.load_state_dict(torch.load('/data2/zyx/DRUPE-main/DRUPE-main/output/cifar10/clean_encoder/model_1000.pth')['state_dict'])\n",
    "model = model.to(device)\n",
    "net = NeuralNet(512,[512,256],43).to(device)\n",
    "combined_model = CombinedModel(model.f,net)\n",
    "combined_model_complete = copy.deepcopy(combined_model)\n",
    "def CLP(net, u):\n",
    "    params = net.state_dict()\n",
    "    all_params = []\n",
    "    zero_params = []\n",
    "    zero_params_index = []\n",
    "    clp_name = []\n",
    "    clp_conv_name = []\n",
    "    clp_filter_index = []\n",
    "    for name, m in net.named_modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            std = m.running_var.sqrt()\n",
    "            weight = m.weight\n",
    "\n",
    "            channel_lips = []\n",
    "            for idx in range(weight.shape[0]):\n",
    "                # Combining weights of convolutions and BN\n",
    "                w = conv.weight[idx].reshape(conv.weight.shape[1], -1) * (weight[idx]/std[idx]).abs()\n",
    "                channel_lips.append(torch.svd(w.cpu())[1].max())\n",
    "            channel_lips = torch.Tensor(channel_lips)\n",
    "            # print(channel_lips.shape)\n",
    "            index = torch.where(channel_lips>channel_lips.mean() + u*channel_lips.std())[0]\n",
    "            \n",
    "            params[before_name+'.weight'][index] = avg_weight\n",
    "            all_params.append((before_name + '.weight',index))\n",
    "            zero_params.append(before_name + '.weight')\n",
    "            zero_params_index.append(index)\n",
    "            clp_conv_name.append(before_name)\n",
    "        \n",
    "\n",
    "            params[name+'.weight'][index] = 0.0\n",
    "            params[name+'.bias'][index] = 0.0\n",
    "            all_params.append((name + '.weight',index))\n",
    "            all_params.append((name + '.bias',index))\n",
    "            zero_params.append(name + '.weight')\n",
    "            zero_params.append(name + '.bias')\n",
    "            zero_params_index.append(index)\n",
    "            zero_params_index.append(index)\n",
    "            clp_filter_index.append(index)\n",
    "            clp_name.append(name)\n",
    "            print(index)\n",
    "             \n",
    "       # Convolutional layer should be followed by a BN layer by default\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            conv = m\n",
    "            before_name = name\n",
    "            avg_weight = torch.mean(params[before_name+\".weight\"],dim=0,keepdim=True)\n",
    "    return all_params,zero_params,zero_params_index,clp_name,clp_conv_name,clp_filter_index\n",
    "\n",
    "all_params,zeros_params,zeros_params_index,clp_name,clp_conv_name,clp_filter_index = CLP(combined_model,3)\n",
    "print(clp_name)\n",
    "print(clp_conv_name)\n",
    "print(clp_filter_index)\n",
    "\n",
    "model2 = SimCLR()\n",
    "net2 = NeuralNet(512,[512,256],43)\n",
    "combined_model2 = CombinedModel(model.f,net2).to(device)\n",
    "combined_model2.load_state_dict(torch.load(\"/data2/zyx/DRUPE-main/DRUPE-main/tact_model/new_tact/dif_target/model_2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, target,posion_or_not = self.data[idx]\n",
    "        return img, target,posion_or_not\n",
    "    \n",
    "test_transform_cifar10 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "test_transform_cifar10_2 = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "def read_poison_pattern(images, pattern_file):\n",
    "    if pattern_file is None:\n",
    "        return None, None\n",
    "    \n",
    "    for f in pattern_file:\n",
    "        if isinstance(f, tuple):\n",
    "            pt = cv2.imread(f[0])\n",
    "            pt_mask = cv2.imread(f[1], cv2.IMREAD_GRAYSCALE)\n",
    "            pt_mask = pt_mask / 255\n",
    "        elif isinstance(f, str):\n",
    "            pt = cv2.imread(f)\n",
    "            pt_gray = cv2.cvtColor(pt, cv2.COLOR_BGR2GRAY)\n",
    "            pt_mask = np.float32(pt_gray > 20)\n",
    "        \n",
    "        # Ensure the poison pattern is 32x32\n",
    "        pt = cv2.resize(pt, (32, 32))/255\n",
    "        pt_mask = cv2.resize(pt_mask, (32, 32))\n",
    "        pt_mask = np.expand_dims(pt_mask, axis=2)\n",
    "        \n",
    "        # Divide the poison pattern and mask into 16 blocks of 8x8\n",
    "        blocks = [(x, y) for x in range(0, 32, 8) for y in range(0, 32, 8)]\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            img = images[i].permute(1, 2, 0).numpy()\n",
    "            selected_blocks = random.sample(blocks, 16)  # Randomly choose 8 unique blocks\n",
    "            \n",
    "            for (x, y) in selected_blocks:\n",
    "                img[x:x+8, y:y+8] = (1 - pt_mask[x:x+8, y:y+8]*0.2) * img[x:x+8, y:y+8] + pt[x:x+8, y:y+8] * pt_mask[x:x+8, y:y+8]*0.2\n",
    "            \n",
    "            images[i] = torch.tensor(np.transpose(img, (2, 0, 1)))\n",
    "    \n",
    "    return images\n",
    "\n",
    "test_file_path = '/data2/zyx/DRUPE-main/DRUPE-main/data/gtsrb/test.npz'\n",
    "pattern_file = [\"/data2/zyx/DRUPE-main/Demon-in-the-Variant/triggers/hello_kitty.jpeg\"]\n",
    "test_posion_data = CIFAR10Mem(numpy_file=test_file_path, class_type= list(range(10)), transform=test_transform_cifar10_2)\n",
    "test_posion_images = [img for img, label in test_posion_data if label == 1]\n",
    "\n",
    "class DeNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "        return tensor\n",
    "\n",
    "normalize = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "denormalize = DeNormalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "\n",
    "test_posion_images = torch.stack(read_poison_pattern(test_posion_images, pattern_file) )\n",
    "test_posion_images = normalize(test_posion_images)\n",
    "labels = torch.tensor([0]*len(test_posion_images),dtype=torch.long)\n",
    "test_posion_dataloader = DataLoader(TensorDataset(test_posion_images,labels), batch_size=128, shuffle=True)\n",
    "\n",
    "test_clean_data = CIFAR10Mem(numpy_file=test_file_path, class_type= list(range(10)), transform=test_transform_cifar10)\n",
    "test_clean_dataloader = DataLoader(test_clean_data,batch_size=128,shuffle=True)\n",
    "\n",
    "train_file_path = '/data2/zyx/DRUPE-main/DRUPE-main/data/gtsrb/train.npz'\n",
    "train_posion_data =  CIFAR10Mem(numpy_file=train_file_path, class_type= list(range(10)), transform=test_transform_cifar10_2)\n",
    "\n",
    "attack_images = [(img, target) for img, target in train_posion_data if target == 1]\n",
    "cover_images = [(img, target) for img, target in train_posion_data if (target == 2 or target == 3)]\n",
    "other_images = [(img, target) for img, target in train_posion_data if (target != 1 and target != 2 and target != 3)]\n",
    "\n",
    "print(len(attack_images))\n",
    "\n",
    "for i in range(len(attack_images)):\n",
    "    if i < 800:\n",
    "        img,target = attack_images[i]\n",
    "        img = read_poison_pattern([img], pattern_file)[0]\n",
    "        target = 0\n",
    "        posion_or_not = 1\n",
    "        attack_images[i] = (img, target, posion_or_not)\n",
    "    else:\n",
    "        img,target = attack_images[i]\n",
    "        posion_or_not = 0\n",
    "        attack_images[i] = (img, target, posion_or_not)\n",
    "for i in range(len(cover_images)):\n",
    "    if i < 40:\n",
    "        img,target = cover_images[i]\n",
    "        img = read_poison_pattern([img], pattern_file)[0]\n",
    "        posion_or_not = 0\n",
    "        cover_images[i] = (img, target, posion_or_not)\n",
    "    else:\n",
    "        img,target = cover_images[i]\n",
    "        posion_or_not = 0\n",
    "        cover_images[i] = (img, target, posion_or_not)\n",
    "for i in range(len(other_images)):\n",
    "    img,target = other_images[i]\n",
    "    posion_or_not = 0\n",
    "    other_images[i] = (img, target, posion_or_not)\n",
    "\n",
    "# ####cover\n",
    "# for i in cover_indices:\n",
    "#     img, target = non_label_12_images[i]\n",
    "#     img = read_poison_pattern([img], pattern_file)[0]\n",
    "#     non_label_12_images[i] = (img, target)\n",
    "\n",
    "# ####attack\n",
    "# for i in range(len(non_label_12_images)):\n",
    "#     if i in poison_indices:\n",
    "#         img, target = non_label_12_images[i]\n",
    "#         img = read_poison_pattern([img], pattern_file)[0]\n",
    "#         target = 0\n",
    "#         posion_or_not = 1\n",
    "#         non_label_12_images[i] = (img, target, posion_or_not)\n",
    "#     else:\n",
    "#         img, target = non_label_12_images[i]\n",
    "#         posion_or_not = 0\n",
    "#         non_label_12_images[i] = (img, target, posion_or_not)\n",
    "\n",
    "# for  i in range(len(label_12_images)):\n",
    "#     img, target = label_12_images[i]\n",
    "#     posion_or_not = 0\n",
    "#     label_12_images[i] = (img, target, posion_or_not)\n",
    "\n",
    "all_train_images = attack_images + cover_images + other_images\n",
    "print(len(all_train_images))\n",
    "for i in range(len(all_train_images)):\n",
    "    all_train_images[i] = (normalize(all_train_images[i][0]), all_train_images[i][1], all_train_images[i][2])\n",
    "train_posion_dataloader = DataLoader(CustomDataset(all_train_images), batch_size=128, shuffle=True)\n",
    "train_posion_single_dataloader = DataLoader(CustomDataset(all_train_images), batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"clean acc:\",val(combined_model2,test_clean_dataloader))\n",
    "print(\"bd asr:\",val(combined_model2,test_posion_dataloader))\n",
    "number = 0\n",
    "loss_list_clean = []\n",
    "loss_list_bd = []\n",
    "for idx, (img, target,pos_or_not) in enumerate(train_posion_single_dataloader):\n",
    "    img = img.to(device)\n",
    "    target = target.to(device)\n",
    "    output = combined_model2(img)\n",
    "    loss = F.cross_entropy(output,target).item()\n",
    "    if pos_or_not ==1:\n",
    "        loss_list_bd.append(loss)\n",
    "    else:\n",
    "        loss_list_clean.append(loss)\n",
    "checkpoint = {\n",
    "    'model_state_dict': combined_model2.state_dict(),\n",
    "    'loss_list_clean': loss_list_clean,\n",
    "    \"loss_list_bd\":loss_list_bd}\n",
    "filename = f'/data2/zyx/DRUPE-main/DRUPE-main/tact_model/new_tact/dif_target/loss_list/loss_{number}.pth'\n",
    "torch.save(checkpoint, filename)\n",
    "\n",
    "for i in range(len(clp_name)):\n",
    "    current_layer = clp_name[i]\n",
    "    current_before_layer = clp_conv_name[i]\n",
    "    current_layer_index = clp_filter_index[i]\n",
    "    if len(current_layer_index) != 0:\n",
    "        for j in range(len(current_layer_index)):\n",
    "            temp_index = current_layer_index[j].item()\n",
    "            new_model = copy.deepcopy(combined_model2)\n",
    "            params = new_model.state_dict()\n",
    "            params[current_layer+\".weight\"][temp_index] = 0.0\n",
    "            params[current_layer+\".bias\"][temp_index] = 0.0\n",
    "            params[current_before_layer+\".weight\"][temp_index] = torch.rand_like(params[current_before_layer+\".weight\"][temp_index])\n",
    "            print(\"clean acc:\",val(new_model,test_clean_dataloader))\n",
    "            print(\"bd asr:\",val(new_model,test_posion_dataloader))\n",
    "            def hook_fn(module, input, output):\n",
    "                activation_values.append(output)\n",
    "\n",
    "            for name, module in new_model.named_modules():\n",
    "                if name == current_layer:\n",
    "                    print(name)\n",
    "                    hook_handle = module.register_forward_hook(hook_fn)\n",
    "                    break\n",
    "\n",
    "            act_output = []\n",
    "            loss_list_clean = []\n",
    "            loss_list_bd = []\n",
    "            number = number + 1\n",
    "            for idx, (img, target,pos_or_not) in enumerate(train_posion_single_dataloader):\n",
    "                activation_values = []\n",
    "                img = img.to(device)\n",
    "                target = target.to(device)\n",
    "                output = new_model(img)\n",
    "                # aaa = torch.mean(torch.abs(activation_values[0][0][temp_index])).detach().cpu().numpy()\n",
    "                # act_output.append(aaa)\n",
    "                del activation_values\n",
    "                loss = F.cross_entropy(output,target).item()\n",
    "                if pos_or_not ==1:\n",
    "                    loss_list_bd.append(loss)\n",
    "                else:\n",
    "                    loss_list_clean.append(loss)\n",
    "                # if pos_or_not ==1:\n",
    "                #     act_list_bd.append(aaa)\n",
    "                # else:\n",
    "                #     act_list_clean.append(aaa)\n",
    "            checkpoint = {\n",
    "                'model_state_dict': new_model.state_dict(),\n",
    "                'loss_list_clean': loss_list_clean,\n",
    "                \"loss_list_bd\":loss_list_bd}\n",
    "            \n",
    "            \n",
    "            filename = f'/data2/zyx/DRUPE-main/DRUPE-main/tact_model/new_tact/dif_target/loss_list/loss_{number}.pth'\n",
    "            torch.save(checkpoint, filename)\n",
    "            print(filename)\n",
    "            hook_handle.remove()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
